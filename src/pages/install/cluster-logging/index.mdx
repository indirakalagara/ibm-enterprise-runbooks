---
title: Cluster Logging in OCP 4.5
---

import Globals from 'gatsby-theme-carbon/src/templates/Globals';

<PageDescription>
</PageDescription>

<Tabs>

<Tab label="Installing Cluster logging with EFK stack on OCP 4.5" open="true">
##Pre-reqs:
    1.	Default cluster logging installation deploys 16G of memory for both memory requests and memory limits.
    2.	A persistent volume is required for each Elasticsearch deployment to have one data volume per data node. On OpenShift Container Platform this is achieved using Persistent Volume Claims.
        The Elasticsearch Operator names the PVCs using the Elasticsearch resource name

###Check Storage permissions:
    https://cloud.ibm.com/docs/containers?topic=containers-cs_troubleshoot_storage#missing_permissions


##Installing cluster logging using the CLI
    1. Create a Namespace for the Elasticsearch Operator.
            namespace:  openshift-operators-redhat
    2. Create a Namespace for the Cluster Logging Operator
            namespace: openshift-logging
    3. Install the Elasticsearch Operator by creating the following objects:
        a. Create an Operator Group object YAML file (for example, eo-og.yaml) for the Elasticsearch operator:
        b. Create a Subscription object YAML file (for example, eo-sub.yaml) to subscribe a Namespace to the Elasticsearch Operator.
            Specify redhat-operators. If your OpenShift Container Platform cluster is installed on a restricted network, also known as a disconnected cluster, specify the name of the CatalogSource object created when you configured the Operator Lifecycle Manager (OLM).
        c. oc create -f eo-sub.yaml
        d. Verify the Operator installation:
                oc get csv --all-namespaces
    4. Install the Cluster Logging Operator by creating the following objects:
        a.	Create an OperatorGroup for the Cluster Logging Operator:
            namespace: openshift-logging 
            targetNamespaces:
            - openshift-logging 
                oc create -f clo-og.yaml

        b.	Create a Subscription object 
                namespace: openshift-logging
                channel: "4.5" 
                source: redhat-operators 
                oc create -f clo-sub.yaml

            c.	Verify the Operator installation.
                There should be a Cluster Logging Operator in the openshift-logging Namespace. The Version number might be different than shown.

    5. Create a Cluster Logging instance:

        Verify the storage class, to set in the cluster instance or leave it blank if it is default block storage 
        oc create -f clo-instance.yaml
        oc get deployment

        View the nodes where the Fluentd are deployed.
            oc get pods --all-namespaces -o wide  | grep "fluentd"

            oc get pods --selector component=fluentd -o wide -n openshift-logging

        Verity:
            oc get pod -n openshift-logging --selector component=elasticsearch

            oc exec -n openshift-logging -c elasticsearch elasticsearch-cdm-q1cotxre-1-57bdd5f94f-g7v7w -- es_cluster_health

            Check status â€“ Green

        Verify elastic search cron jobs are created
            oc get CronJob

        View Elastic serach indices

            oc exec -c elasticsearch elasticsearch-cdm-q1cotxre-1-57bdd5f94f-g7v7w -- indices

    6. Get Kibana route    
            <img></img>

    7. To create kibana indexes, check the roles

            A user must have the cluster-admin role, the cluster-reader role, or both roles to list the infra and audit indices in Kibana.

            Elasticsearch documents must be indexed before you can create index patterns. This is done automatically, but it might take a few minutes in a new or updated cluster.
            oc auth can-i get pods/logs -n default

            Create an index pattern  app-*

            In RHOCP 4.5, the browser redirects you to Kibana's Create index pattern page under Management. Create a new index pattern app-* to select all the Elasticsearch indices used for your application logs. Navigate to the Discover page to view the application logs generated by the deployed application.



</Tab>
<Tab label="Errors">
Error :
    Java.io.IOException: Could not create directory /elasticsearch/persistent/elasticsearch/logs
    https://access.redhat.com/solutions/4431881

</Tab>
<Tab label="References">
OpenShift Loggig:
https://docs.openshift.com/container-platform/4.5/logging/config/cluster-logging-storage-considerations.html#cluster-logging-storage
Create inded pattern
https://www.ibm.com/support/knowledgecenter/SSCSJL_4.2.x/guides/guide-app-logging-ocp-4.2/app-logging-ocp-4.2.html


</Tab>

</Tabs>

